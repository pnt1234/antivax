{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vaccination-Stance Classification\n",
    "\n",
    "The following Jupyter notebook contains the python programs for generating the results given in the paper. The code was written using Python 3. It uses additional python libraries from nltk, pandas, and scikit-learn. Specifically, the following code was developed to classify vaccine-related tweets into 3 classes (pro-vaccine, anti-vaccine, and neutral).\n",
    "\n",
    "To perform the classification, the tweets are preprocessed as follows:\n",
    "- We first apply NLTK's TweetTokenizer() function to convert the tweets into lower case and then segment them into a set of tokens (words, hashtags, and mentions).\n",
    "- Stopwords are removed from the extracted tokens.\n",
    "- We then apply scikit-learn's CountVectorizer() function to count the frequency of each token (including bigrams).\n",
    "\n",
    "After preprocessing, we use scikit-learn's implementation of l1-regularized logistic regression to train the model (with its default regularization parameter, C = 1). Performance of the classifier is evaluated using 10-fold cross validation. Oversampling was performed to the smaller class on the training set to handle the imbalanced class distribution. Results are reported in terms of the overall model accuracy as well as the precision, recall, and F-measure for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../data/'\n",
    "resultdir = '../results/'\n",
    "\n",
    "# Feature extraction parameter\n",
    "ngrams = (1,2)                # extract unigrams and bigrams\n",
    "\n",
    "# Classification parameters\n",
    "oversampling = True           # stratification by oversampling the smaller classes in training set\n",
    "numFolds = 10                 # number of folds for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subroutine Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "def getStopwords():\n",
    "    stopwordlist = set(stopwords.words('english'))\n",
    "    with open(datadir + 'stopwords.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            stopwordlist.add(line.rstrip('\\n'))\n",
    "    \n",
    "    return stopwordlist\n",
    "               \n",
    "def preprocess(sentence):\n",
    "    tkz = TweetTokenizer(preserve_case=False)\n",
    "    stop_words = getStopwords()\n",
    "    temp = []\n",
    "    for word in tkz.tokenize(sentence.lower()):\n",
    "        if word != '' and not (word in stop_words): \n",
    "            temp.append(word)\n",
    "    separator = ' '\n",
    "    return separator.join(temp)\n",
    "\n",
    "def getAllFeatures(sp_mat, features):\n",
    "    vocab = dict([(value, key) for key, value in features.items()])\n",
    "    result = []\n",
    "    for i in range(sp_mat.shape[0]):\n",
    "        p, q = sp_mat[i].nonzero()\n",
    "        temp = ' '.join([vocab[q[j]] for j in range(len(q))])\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5611, 2)\n",
      "Pro-vs-anti class distribution:\n",
      " 0    2422\n",
      " 1    1639\n",
      "-1    1550\n",
      "Name: class, dtype: int64\n",
      " 0    0.431652\n",
      " 1    0.292105\n",
      "-1    0.276243\n",
      "Name: class, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If #vaccines do NOT cause autism  CDC should ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First question asked when someone dies in a c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@CollChris @PedsGeekMD @nnebeluk @somedocs @w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Oh my God  I can't believe we did what we di...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vaccine Safety Study Act (HR 3615) reintroduc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>Here we are pharmaceutical companies coercing ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>@puddleg Don't know! I was trying to find proo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>@amandpms @TheCollectiveQ I was told the same ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5609</th>\n",
       "      <td>@HerbsandDirt Just went to the \"pediatrician\" ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5610</th>\n",
       "      <td>@DrM_Ashraf @ibu0o @Ahammadhu2 @RainyDay30 @ah...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5611 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      X  class\n",
       "0      If #vaccines do NOT cause autism  CDC should ...     -1\n",
       "1      First question asked when someone dies in a c...      1\n",
       "2      @CollChris @PedsGeekMD @nnebeluk @somedocs @w...      1\n",
       "3      \"Oh my God  I can't believe we did what we di...     -1\n",
       "4      Vaccine Safety Study Act (HR 3615) reintroduc...      1\n",
       "...                                                 ...    ...\n",
       "5606  Here we are pharmaceutical companies coercing ...     -1\n",
       "5607  @puddleg Don't know! I was trying to find proo...     -1\n",
       "5608  @amandpms @TheCollectiveQ I was told the same ...     -1\n",
       "5609  @HerbsandDirt Just went to the \"pediatrician\" ...     -1\n",
       "5610  @DrM_Ashraf @ibu0o @Ahammadhu2 @RainyDay30 @ah...     -1\n",
       "\n",
       "[5611 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rawdata = pd.read_csv(datadir + \"pro_anti.csv\",encoding = 'utf-8', header = 'infer')\n",
    "print(rawdata.shape)\n",
    "\n",
    "print('Pro-vs-anti class distribution:')\n",
    "distrib = rawdata['class'].value_counts()\n",
    "print(distrib)\n",
    "probs = distrib/sum(distrib)\n",
    "print(probs)\n",
    "\n",
    "rawdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#vaccines cause autism cdc qualms studying aut...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first question asked someone dies car crash ? ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@collchris @pedsgeekmd @nnebeluk @somedocs @we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" oh god believe . \" it'd terrible say words p...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vaccine safety study act ( hr 3615 ) reintrodu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>pharmaceutical companies coercing governments ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>@puddleg know ! trying find proof mmr vaccine ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>@amandpms @thecollectiveq told thing 1993 gave...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5609</th>\n",
       "      <td>@herbsanddirt went \" pediatrician \" said 1 yea...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5610</th>\n",
       "      <td>@drm_ashraf @ibu0o @ahammadhu2 @rainyday30 @ah...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5611 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      X  class\n",
       "0     #vaccines cause autism cdc qualms studying aut...     -1\n",
       "1     first question asked someone dies car crash ? ...      1\n",
       "2     @collchris @pedsgeekmd @nnebeluk @somedocs @we...      1\n",
       "3     \" oh god believe . \" it'd terrible say words p...     -1\n",
       "4     vaccine safety study act ( hr 3615 ) reintrodu...      1\n",
       "...                                                 ...    ...\n",
       "5606  pharmaceutical companies coercing governments ...     -1\n",
       "5607  @puddleg know ! trying find proof mmr vaccine ...     -1\n",
       "5608  @amandpms @thecollectiveq told thing 1993 gave...     -1\n",
       "5609  @herbsanddirt went \" pediatrician \" said 1 yea...     -1\n",
       "5610  @drm_ashraf @ibu0o @ahammadhu2 @rainyday30 @ah...     -1\n",
       "\n",
       "[5611 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = rawdata.copy()\n",
    "data['X'] = data['X'].apply(preprocess)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5611, 15948)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = tf = CountVectorizer(max_df=0.95, min_df=2/data.shape[0], ngram_range=ngrams)    \n",
    "X = vectorizer.fit_transform(data['X'].values)\n",
    "features = vectorizer.vocabulary_\n",
    "Y = rawdata['class']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      " 0    2422\n",
      " 1    1639\n",
      "-1    1550\n",
      "Name: class, dtype: int64\n",
      " 0    0.431652\n",
      " 1    0.292105\n",
      "-1    0.276243\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Class distribution:')\n",
    "distrib = Y.value_counts()\n",
    "print(distrib)\n",
    "\n",
    "probs = distrib/sum(distrib)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation\n",
    "\n",
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9791570881226054\n",
      "Test accuracy:0.8879003558718861\n",
      "\n",
      "Fold 2:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9801334546557476\n",
      "Test accuracy:0.8894830659536542\n",
      "\n",
      "Fold 3:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9791953495487227\n",
      "Test accuracy:0.8966131907308378\n",
      "\n",
      "Fold 4:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9792913023469857\n",
      "Test accuracy:0.910873440285205\n",
      "\n",
      "Fold 5:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9803113553113553\n",
      "Test accuracy:0.9037433155080213\n",
      "\n",
      "Fold 6:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9774297558728696\n",
      "Test accuracy:0.9162210338680927\n",
      "\n",
      "Fold 7:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9806166056166056\n",
      "Test accuracy:0.8948306595365418\n",
      "\n",
      "Fold 8:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9801934592353754\n",
      "Test accuracy:0.9162210338680927\n",
      "\n",
      "Fold 9:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9819240196078431\n",
      "Test accuracy:0.8823529411764706\n",
      "\n",
      "Fold 10:\n",
      "[LibLinear]\n",
      "Train accuracy:0.9801859472641365\n",
      "Test accuracy:0.9144385026737968\n",
      "Confusion Matrix:\n",
      "[[1344   40  166]\n",
      " [  25 2349   48]\n",
      " [ 175  100 1364]]\n",
      "Accuracy = 0.9012653715915167\n",
      "Micro F1 = 0.9012653715915167\n",
      "Macro F1 = 0.8911337616578905\n",
      "Weighted F1 = 0.9006278998189661\n",
      "Accuracy = 0.9012653715915167\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "kf = KFold(n_splits=numFolds, shuffle=True, random_state=1)\n",
    "fold = 0\n",
    "Ypred = Y.copy()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    fold += 1\n",
    "    print('\\nFold %d:' % (fold))\n",
    "    \n",
    "    train = pd.DataFrame(X[train_index].toarray())\n",
    "    train['class'] = Y[train_index].tolist()\n",
    "    \n",
    "    if oversampling:\n",
    "        max_size = train['class'].value_counts().max()\n",
    "\n",
    "        lst = [train]\n",
    "        for class_index, group in train.groupby('class'):\n",
    "            lst.append(group.sample(max_size-len(group), replace=True))\n",
    "        data = pd.concat(lst)\n",
    "    else:\n",
    "        data = train\n",
    "        \n",
    "    Y_train = data['class']\n",
    "    X_train = data.drop(['class'],axis=1)\n",
    "    X_train = csr_matrix(X_train)\n",
    "\n",
    "    clf = LogisticRegression(verbose=1, solver='liblinear',random_state=1,penalty='l1',max_iter=5000) \n",
    "    clf.fit(X_train,Y_train)\n",
    "\n",
    "    pred_train = clf.predict(X_train)\n",
    "    pred_test = clf.predict(X[test_index])\n",
    "    Ypred[test_index] = pred_test\n",
    "\n",
    "    print('\\nTrain accuracy:' + str(accuracy_score(Y_train, pred_train)))\n",
    "    print('Test accuracy:' + str(accuracy_score(Y[test_index], pred_test)))\n",
    "    \n",
    "    if fold == 1:\n",
    "        cm = confusion_matrix(Y[test_index], pred_test)\n",
    "    else:\n",
    "        cm = cm + confusion_matrix(Y[test_index], pred_test)\n",
    "    \n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Accuracy =\", sum(np.diag(cm))/sum(sum(cm)))\n",
    "print(\"Micro F1 =\", f1_score(Y, Ypred, average='micro'))\n",
    "print(\"Macro F1 =\", f1_score(Y, Ypred, average='macro'))\n",
    "print(\"Weighted F1 =\", f1_score(Y, Ypred, average='weighted'))\n",
    "print(\"Accuracy =\", accuracy_score(Y, Ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class -1:\n",
      "   Precision = 0.8704663212435233\n",
      "   Recall = 0.8670967741935484\n",
      "   F-measure = 0.8687782805429864\n",
      "Class 0:\n",
      "   Precision = 0.9437525110486139\n",
      "   Recall = 0.9698596201486375\n",
      "   F-measure = 0.9566279780085523\n",
      "Class 1:\n",
      "   Precision = 0.8643852978453739\n",
      "   Recall = 0.8322147651006712\n",
      "   F-measure = 0.8479950264221325\n"
     ]
    }
   ],
   "source": [
    "print('Class -1:')\n",
    "prec = cm[0][0]/cm[:,0].sum()\n",
    "recall = cm[0][0]/cm[0,:].sum()\n",
    "f1 = 2*prec*recall/(prec + recall)\n",
    "print('   Precision =', prec)\n",
    "print('   Recall =', recall)\n",
    "print('   F-measure =', f1)\n",
    "print('Class 0:')\n",
    "prec = cm[1][1]/cm[:,1].sum()\n",
    "recall = cm[1][1]/cm[1,:].sum()\n",
    "f1 = 2*prec*recall/(prec + recall)\n",
    "print('   Precision =', prec)\n",
    "print('   Recall =', recall)\n",
    "print('   F-measure =', f1)\n",
    "print('Class 1:')\n",
    "prec = cm[2][2]/cm[:,2].sum()\n",
    "recall = cm[2][2]/cm[2,:].sum()\n",
    "f1 = 2*prec*recall/(prec + recall)\n",
    "print('   Precision =', prec)\n",
    "print('   Recall =', recall)\n",
    "print('   F-measure =', f1)\n",
    "\n",
    "rawdata['Predicted'] = Ypred\n",
    "rawdata['Processed'] = pd.DataFrame(getAllFeatures(X, features))\n",
    "rawdata.to_csv(resultdir + 'pro_vs_anti_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
